{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is parameter?**"
      ],
      "metadata": {
        "id": "RkJJf5hqiy5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans- In Machine Learning, a parameter is a configuration value that a model learns from the data during training. These values determine how the model makes predictions or classifications based on input data.\n",
        "\n",
        "\n",
        "   example:-   y = mx+c    where m and c are parameters\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QEu97Shnik-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. (a)What is correlation?**\n",
        "\n",
        "**(b)what does negative correlation mean?**"
      ],
      "metadata": {
        "id": "tVUqhxSdjv-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - correlation measures how strongly two variables are related. A positive correlation means they increase together, while a negative correlation means one decreases as the other increases. Examples-\n",
        "\n",
        "1.   Alcohol consumption increases, No. of year to live decrease.\n",
        "2.   Area of house increases, price of house aslo increases."
      ],
      "metadata": {
        "id": "rEGJ6mfokCsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Define Machine Learning. What are the main components in Machine Learning?**"
      ],
      "metadata": {
        "id": "gfhTl2cJkQfG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - Machine Learning is a method where systems learn from data to make predictions or decisions without explicit programming.\n",
        "   Main components are:-\n",
        "\n",
        "1.  Data - Input information.\n",
        "2.  Model - Algorithm for predictions.\n",
        "3.  Features - Relevant input variables.\n",
        "4.  Training - Learning from data.\n",
        "5.  Evaluation - Testing performance.\n",
        "7.  Prediction - Generating outputs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3iZL1fbQnBer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. How does loss value help in determining whether the model is good or not?**"
      ],
      "metadata": {
        "id": "-3OGQvPFxnhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - The loss value measures how far the model's predictions are from the actual values.\n",
        "\n",
        "\n",
        "*   Low loss: Model predictions are close to the actual values, meaning it's performing well.\n",
        "*   High loss: Model predictions are inaccurate, indicating poor performance.\n"
      ],
      "metadata": {
        "id": "KCrDNf1Zx78T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What are continuous and categorical variables?**"
      ],
      "metadata": {
        "id": "cFwAo2CSycQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - Continuous variables are numeric and can take any value within a range. They are measured and can have decimal points. example - height, weight.\n",
        "\n",
        " Categorical variables represent categories or labels and have distinct, non-numeric values. example - Gender, colour.\n"
      ],
      "metadata": {
        "id": "XTduUhGJyt9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. How do we handle categorical variables in Machine Learning? What are the common techniques?**"
      ],
      "metadata": {
        "id": "pc9ECZlHzWKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - To handle categorical variables in Machine Learning:\n",
        "*   One-Hot Encoding: Creates binary columns for each category.\n",
        "*   Label Encoding: Converts categories into unique integers.\n",
        "*   Ordinal Encoding: Assigns numbers to ordered categories.\n",
        "*   Target Encoding: Replaces categories with the target variable's mean."
      ],
      "metadata": {
        "id": "Nr4S_e2Dzus0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What do you mean by training and testing a dataset?**"
      ],
      "metadata": {
        "id": "LHQRQ7OA0PRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - Training: Teaching the model using a portion of the data.\n",
        "\n",
        "Testing: Evaluating the model's performance on unseen data."
      ],
      "metadata": {
        "id": "396ty39v0aty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. What is sklearn.preprocessing?**"
      ],
      "metadata": {
        "id": "a-1IlU7w0vhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - sklearn.preprocessing helps prepare data for machine learning by scaling, transforming, and encoding it. Key functions include:\n",
        "*   StandardScaler: Standardizes features.\n",
        "*   MinMaxScaler: Scales features to a range.\n",
        "*   OneHotEncoder: Encodes categorical variables.\n",
        "*   LabelEncoder: Converts labels to numbers."
      ],
      "metadata": {
        "id": "enGdb34a00U_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What is a Test set?**"
      ],
      "metadata": {
        "id": "zpPyrI2Z2bZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - A test set is a portion of the dataset that is used to evaluate the performance of a machine learning model after it has been trained. The test set contains data the model hasn't seen during training, helping assess how well the model generalizes to new, unseen data."
      ],
      "metadata": {
        "id": "wi3Wh9hk2mKg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. How do we split data for model fitting (training and testing) in Python?**"
      ],
      "metadata": {
        "id": "nxGU6g0b2-o4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can split data for model fitting using train_test_split from sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example dataset\n",
        "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]  # Features\n",
        "y = [0, 1, 0, 1, 0]  # Labels\n",
        "\n",
        "# Split data into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train:\", X_train)\n",
        "print(\"X_test:\", X_test)\n",
        "print(\"y_train:\", y_train)\n",
        "print(\"y_test:\", y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISt1V4fM3Z5o",
        "outputId": "47373777-aa67-41b3-d095-0e42fae6ae99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: [[9, 10], [5, 6], [1, 2], [7, 8]]\n",
            "X_test: [[3, 4]]\n",
            "y_train: [0, 0, 0, 1]\n",
            "y_test: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How do you approach a Machine Learning problem?**"
      ],
      "metadata": {
        "id": "BG6VHDvi35AT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - To approach a Machine Learning problem:\n",
        "\n",
        "*   Define the Problem: Understand the goal.\n",
        "*   Collect and Prepare Data: Clean and preprocess the data.\n",
        "*   Split the Data: Divide into training and testing sets.\n",
        "*   Choose a Model: Select the appropriate algorithm.\n",
        "*   Train the Model: Fit the model on the training data.\n",
        "*   Evaluate the Model: Test the model's performance.\n",
        "*   Tune the Model: Optimize hyperparameters.\n",
        "*   Deploy the Model: Use it in real-world applications\n",
        "*   Monitor and Improve: Continuously update the model."
      ],
      "metadata": {
        "id": "hWP-IcJ_3Kta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Why do we have to perform EDA before fitting a model to the data?**"
      ],
      "metadata": {
        "id": "l3sidWIr5e94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - EDA is important before fitting a model because it helps understand the data, detect issues like missing values or outliers, select relevant features, and decide on necessary data transformations. It also guides choosing the right model, leading to better performance and more accurate predictions."
      ],
      "metadata": {
        "id": "Gfrn47NK5mWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. What is correlation?**"
      ],
      "metadata": {
        "id": "tSiqccDbwUYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - correlation measures how strongly two variables are related. A positive correlation means they increase together, while a negative correlation means one decreases as the other increases."
      ],
      "metadata": {
        "id": "lYfmeGn0wejf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. what does negative correlation mean?**"
      ],
      "metadata": {
        "id": "xycecLwnw2nj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - A negative correlation means one variable decreases as the other variable increases.\n",
        "   example - As speed of car increases time taken to reach destination decreases\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0Xy7WBQKw8A5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. How can you find correlation between variables in Python?**"
      ],
      "metadata": {
        "id": "2-lGj8SJ5-AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example dataset\n",
        "data = {\n",
        "    'Feature1': [1, 2, 3, 4, 5],\n",
        "    'Feature2': [5, 4, 3, 2, 1],\n",
        "    'Feature3': [1, 3, 2, 4, 5]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculate the correlation between features\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wFpeq4N6TgG",
        "outputId": "608bf70e-7650-4bd8-d98d-233ebecafa2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Feature1  Feature2  Feature3\n",
            "Feature1       1.0      -1.0       0.9\n",
            "Feature2      -1.0       1.0      -0.9\n",
            "Feature3       0.9      -0.9       1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. What is causation? Explain difference between correlation and causation with an example.**"
      ],
      "metadata": {
        "id": "J12ljKRa6CqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - Causation means one variable directly causes another.\n",
        "\n",
        "Correlation means two variables are related but one doesn't necessarily cause the other.\n",
        "\n",
        "Example: Ice cream sales and drowning are correlated in summer but ice cream doesn't cause drowning. Smoking causes lung cancer."
      ],
      "metadata": {
        "id": "c3S_zjes6wln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. What is an Optimizer? What are different types of optimizers? Explain each with an example.**"
      ],
      "metadata": {
        "id": "RO73-xPX7BAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - An optimizer in machine learning is an algorithm that adjusts the model's parameters to minimize the loss function, helping the model learn and make accurate predictions.\n",
        "\n",
        "*   Gradient Descent: Updates parameters by moving in the direction of the steepest descent. e.g -  In linear regression, it adjusts the slope and intercept to minimize the error between predicted and actual values.  \n",
        "*   Stochastic Gradient Descent (SGD): Updates after each data point, faster but noisier. e.g - Used in training deep learning models with large datasets, where each update is based on a single data point.\n",
        "*   Mini-Batch Gradient Descent: Uses a small batch of data for updates, balancing speed and stability. e.g - Commonly used in neural networks to speed up training without too much noise.\n",
        "*   Adam: Combines gradient descent with momentum for faster, more efficient convergence. e.g - Frequently used in deep learning, as it combines the benefits of SGD and momentum, making it effective for large datasets.\n",
        "*   RMSprop: Adjusts learning rate based on recent gradients, useful for noisy data. e.g -  Often used in recurrent neural networks (RNNs) or when training models on time-series data."
      ],
      "metadata": {
        "id": "ZrHm3pkdKuNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. What is sklearn.linear_model ?**"
      ],
      "metadata": {
        "id": "sihsMpVKMKR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - sklearn.linear_model is a module in Scikit-learn that provides linear models for machine learning. These models are used for tasks like regression and classification."
      ],
      "metadata": {
        "id": "ZwFNHLIhMmPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. What does model.fit() do? What arguments must be given?**"
      ],
      "metadata": {
        "id": "82GmofpzMteE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - The model.fit() function in machine learning is used to train a model using the training data.\n",
        "\n",
        "It fits the model to the training data by adjusting its parameters (like weights) to minimize the error or loss function."
      ],
      "metadata": {
        "id": "P7BjIBvQM4bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Example data (features and labels)\n",
        "X_train = [[1, 2], [2, 3], [3, 4], [4, 5]]  # Features\n",
        "y_train = [0, 0, 1, 1]  # Labels\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on new data\n",
        "X_new = [[1, 1], [5, 5]]\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l1On3PWV4UX",
        "outputId": "e8dfa2b1-db70-4c52-d212-c17b9d238dd1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**19. What does model.predict() do? What arguments must be given?**"
      ],
      "metadata": {
        "id": "lNCrm9IENgKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.predict() is used to make predictions on new data after the model is trained.\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Example data\n",
        "X_train = [[1], [2], [3], [4]]\n",
        "y_train = [1, 2, 3, 4]\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on new data\n",
        "X_new = [[5], [6]]\n",
        "predictions = model.predict(X_new)\n",
        "\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9qeuItkN83x",
        "outputId": "f02bb918-1a87-4c10-a228-f638f5e13213"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5. 6.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**20. What are continuous and categorical variables?**"
      ],
      "metadata": {
        "id": "hrQ9d77DOWc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - Continuous variables are numeric and can take any value within a range. They are measured and can have decimal points. example - height, weight.\n",
        "\n",
        " Categorical variables represent categories or labels and have distinct, non-numeric values. example - Gender, colour.\n"
      ],
      "metadata": {
        "id": "zkJ8T3e3OuAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**21. What is feature scaling? How does it help in Machine Learning?**"
      ],
      "metadata": {
        "id": "ClvCcvn9OtoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - Feature scaling is the process of normalizing or standardizing the range of features (input data) so that they are on a similar scale.\n",
        "\n",
        "It helps by:\n",
        "*   Improving convergence in algorithms (e.g., gradient descent).\n",
        "*   Preventing features with larger values from dominating the model."
      ],
      "metadata": {
        "id": "-Uzy_zVxPCUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**22. How do we perform scaling in Python**"
      ],
      "metadata": {
        "id": "6kpNSztuP8Hg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can perform scaling using the StandardScaler or MinMaxScaler from sklearn.preprocessing.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Example data\n",
        "X_train = [[1, 2], [3, 4], [5, 6]]\n",
        "\n",
        "# Initialize and fit the scaler\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(X_train)\n",
        "\n",
        "print(scaled_data)\n"
      ],
      "metadata": {
        "id": "eLE3ZmAbjKJM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d590d77-1cd1-403e-ed33-18f9df427b4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.22474487 -1.22474487]\n",
            " [ 0.          0.        ]\n",
            " [ 1.22474487  1.22474487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pimMETDNhqKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53be5fd9-0cc2-4fd0-cd44-1664c08bdb5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0. ]\n",
            " [0.5 0.5]\n",
            " [1.  1. ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Example data\n",
        "X_train = [[1, 2], [3, 4], [5, 6]]\n",
        "\n",
        "# Initialize and fit the scaler\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(X_train)\n",
        "\n",
        "print(scaled_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**23. What is sklearn.preprocessing?**"
      ],
      "metadata": {
        "id": "-THmkp64iZvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - sklearn.preprocessing helps prepare data for machine learning by scaling, transforming, and encoding it. Key functions include:\n",
        "*   StandardScaler: Standardizes features.\n",
        "*   MinMaxScaler: Scales features to a range.\n",
        "*   OneHotEncoder: Encodes categorical variables.\n",
        "*   LabelEncoder: Converts labels to numbers."
      ],
      "metadata": {
        "id": "AQtSO_8RRDM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**24. How do we split data for model fitting (training and testing) in Python?**"
      ],
      "metadata": {
        "id": "CUKYsJAjRGEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can split data for model fitting using train_test_split from sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example dataset\n",
        "X = [[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]]  # Features\n",
        "y = [0, 1, 0, 1, 0]  # Labels\n",
        "\n",
        "# Split data into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"X_train:\", X_train)\n",
        "print(\"X_test:\", X_test)\n",
        "print(\"y_train:\", y_train)\n",
        "print(\"y_test:\", y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e3df0f-b42e-48cb-faff-222ae3313712",
        "id": "3uj01HQ8RmJh"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: [[9, 10], [5, 6], [1, 2], [7, 8]]\n",
            "X_test: [[3, 4]]\n",
            "y_train: [0, 0, 0, 1]\n",
            "y_test: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**25. Explain data encoding?**"
      ],
      "metadata": {
        "id": "I9DP3hVCRtzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans - Data encoding is the process of converting categorical data (non-numeric) into a numeric format that machine learning models can understand. common types of Encoding are Label Encoding and One- Hot Encoding."
      ],
      "metadata": {
        "id": "VfXRC9UaSIBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "encoded_data = le.fit_transform(['cat', 'dog', 'cat', 'bird'])\n",
        "print(encoded_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONtvLkIbSO-l",
        "outputId": "2f7da4cc-cff8-406a-9d27-aa605e47b2a7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One- Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "data = np.array([['cat'], ['dog'], ['cat'], ['bird']])\n",
        "\n",
        "# Initialize the encoder and fit/transform\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "encoded_data = encoder.fit_transform(data)\n",
        "\n",
        "print(encoded_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYrL05xxTO3n",
        "outputId": "a68539c9-45ab-45db-e999-f4e858bb0a84"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bntPor9rTY8l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}